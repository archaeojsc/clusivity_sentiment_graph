{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eCGh-LW9P4z"
      },
      "source": [
        "# Set up Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45j72trbTirG",
        "outputId": "39cc65b6-fbfa-48d3-ae8d-5121adbb44a7"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "e22da45e-6fcd-4adc-ef54-9c267923cb4b"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K9AO7O4_lSi",
        "outputId": "659f80ad-c9fe-4e2b-d3df-42fa6d3e8a0b"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaz44az22Zsp"
      },
      "source": [
        "## Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocMf7Q1p89lO",
        "outputId": "58286174-4c61-4f60-8964-d7bf75aca4ff"
      },
      "outputs": [],
      "source": [
        "!pip install cdlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HCQKUIObdhR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import cdlib\n",
        "from cdlib import viz\n",
        "from cdlib import evaluation\n",
        "import community\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.stats import spearmanr\n",
        "import sklearn.metrics\n",
        "import scipy.spatial.distance\n",
        "from sklearn.metrics.pairwise import chi2_kernel\n",
        "\n",
        "from operator import itemgetter\n",
        "import copy\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# most_valuable_edge Functions for Girvin-Newman\n",
        "from networkx.algorithms.centrality import edge_betweenness_centrality\n",
        "\n",
        "# Clustering Algorithms\n",
        "from networkx.algorithms.community.asyn_fluid import asyn_fluidc\n",
        "from networkx.algorithms.community.centrality import girvan_newman\n",
        "from networkx.algorithms.community.kernighan_lin import kernighan_lin_bisection\n",
        "from networkx.algorithms.community.modularity_max import greedy_modularity_communities\n",
        "from networkx.algorithms.community.quality import modularity\n",
        "from networkx.algorithms.community.quality import performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ap1C9fD2eq6"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "XDvI9tbFAYXn",
        "outputId": "72119176-ea2d-4c96-a659-0e20421e7688"
      },
      "outputs": [],
      "source": [
        "discourse_df = pd.read_pickle('NST03_extracted_features.pickle')\n",
        "\n",
        "discourse_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bykU-XQNsK_Q",
        "outputId": "b428dbab-039c-43a1-eb93-9f489b7acfab"
      },
      "outputs": [],
      "source": [
        "discourse_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "v3OS9sACsme6",
        "outputId": "81ec70dc-6442-47b5-d07b-d8fd13d86f77"
      },
      "outputs": [],
      "source": [
        "feats_cols = ['id', 'tweet category', 'retweet_count', 'favorite_count', \n",
        "             'is_quote_status', 'is_retweet', 'is_reply', 'been_retweeted', \n",
        "             'incl_affil_score', 'incl_assoc_score', 'excl_affil_score', \n",
        "             'excl_assoc_score', 'abs_terms_score'\n",
        "             ]\n",
        "\n",
        "discourse_feats_df = discourse_df[feats_cols]\n",
        "\n",
        "discourse_feats_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHpvHeYp1Ao7"
      },
      "source": [
        "# Matrix Construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-z5XPzR2nqv"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "Used for testing different similarity and adjacency methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUyaDbe8b-x8"
      },
      "outputs": [],
      "source": [
        "# Probability threshold function\n",
        "\n",
        "\n",
        "def probThreshold(data, threshold: float = 0.01):\n",
        "  return np.where(data < threshold, 0, data)\n",
        "\n",
        "# Similarity measures\n",
        "\n",
        "def simchiSq(data):\n",
        "  chi_sim = chi2_kernel(data)\n",
        "  return chi_sim\n",
        "\n",
        "\n",
        "def simAbsCorr(data):\n",
        "  S = np.absolute(np.corrcoef(data))\n",
        "  return S\n",
        "\n",
        "\n",
        "def simSignedCorr(data):\n",
        "  S = (1 + np.corrcoef(data)) / 2\n",
        "  return S\n",
        "\n",
        "# Adjacency functions\n",
        "\n",
        "\n",
        "def powerAdj(SimMat, Beta: int = 6):\n",
        "  A = SimMat ** Beta\n",
        "  np.fill_diagonal(A, 0)\n",
        "  return A\n",
        "\n",
        "\n",
        "def signumAdj(SimMat, tau: float = 0.0):\n",
        "  A = np.where(SimMat < tau, 0, 1)\n",
        "  np.fill_diagonal(A, 0)\n",
        "  return A\n",
        "\n",
        "# Topological Overlap Matrix function\n",
        "\n",
        "\n",
        "def TOMadjacency(AdjMat, threshold_quantile: float = 0.8):\n",
        "  '''\n",
        "  TOMadjacency calculates an adjacency matrix by the network overlap of nodes\n",
        "  in a weighted, undirected graph.\n",
        "  '''\n",
        "  # Calculate common neighbors of each node\n",
        "  L = AdjMat.dot(AdjMat.T)\n",
        "\n",
        "  # Calculate connectivity of node\n",
        "  Krow = AdjMat.sum(axis=1)\n",
        "  Kcol = AdjMat.sum(axis=0)\n",
        "  Kmin = np.array([np.minimum(k_i, Kcol) for k_i in Krow])\n",
        "\n",
        "  # Topological overlap\n",
        "  TOM = (L + AdjMat) / (Kmin + 1 - AdjMat)\n",
        "\n",
        "  TOM_filtered = np.where(\n",
        "    TOM >= np.quantile(\n",
        "      TOM, threshold_quantile), TOM, 0)\n",
        "\n",
        "  np.fill_diagonal(TOM_filtered, 0)\n",
        "\n",
        "  TOMlower = np.tril(TOM_filtered)\n",
        "\n",
        "  TOMsparse = csr_matrix(TOMlower)\n",
        "\n",
        "  return TOMsparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwe07n44-HqQ"
      },
      "source": [
        "## Discourse Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IG5o2l8Y9-vN"
      },
      "source": [
        "Create `numpy` array of discourse features: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1KIeQZt-9Eb",
        "outputId": "a6d8f84e-6e29-4934-aae9-a91f23962ddd"
      },
      "outputs": [],
      "source": [
        "discourse_feats_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3HzzrjVamFo"
      },
      "outputs": [],
      "source": [
        "disc_cols = ['incl_affil_score', 'incl_assoc_score', 'excl_affil_score',\n",
        "             'excl_assoc_score', 'abs_terms_score']\n",
        "\n",
        "tweet_ids = discourse_feats_df['id'].values\n",
        "\n",
        "disc_arr = discourse_feats_df[disc_cols].values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNwI2Z6lbB0t"
      },
      "source": [
        "#### Find and filter tweets with no discourse scores\n",
        "\n",
        "When tweets have no scores at all across all features, their similarity and adjacency cannot be calculated and so need to be filtered from the analysis. These \"no feature\" tweets constitute a separate block that can be considerd its own cluster in *addition* to the network communities identified below. These shoudl be analyzed by other\n",
        "methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TpfFv5BsNwD",
        "outputId": "e7b13539-26c6-44ed-c766-8ae54937169b"
      },
      "outputs": [],
      "source": [
        "# Find tweets with no values for any feature\n",
        "non_disc_tweets = np.where(np.sum(disc_arr, axis=1)==0)[0].tolist()\n",
        "\n",
        "# List of tweets to keep\n",
        "tweet_keep = np.delete(tweet_ids, non_disc_tweets)\n",
        "\n",
        "# Filter analysis array\n",
        "disc_arr_filt = np.delete(disc_arr, non_disc_tweets, axis=0)\n",
        "\n",
        "disc_arr_filt.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50NQy85obwDs"
      },
      "source": [
        "### Calculate similarity matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "491N5r0pbJdC",
        "outputId": "68513996-fa55-44f5-88b0-7a70c7e7de53"
      },
      "outputs": [],
      "source": [
        "disc_sim = simSignedCorr(disc_arr_filt)\n",
        "\n",
        "disc_sim[:5,:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFdyj7uzb2He"
      },
      "source": [
        "### Calculate adjacency matrix and TOM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2rOdemXbu9L",
        "outputId": "7d9a75c8-7bf1-44f3-bc6f-b607c6d52a6e"
      },
      "outputs": [],
      "source": [
        "disc_adj = powerAdj(disc_sim, Beta=6)\n",
        "disc_TOM = TOMadjacency(disc_adj, threshold_quantile=0.85)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8VArLKucw4V"
      },
      "source": [
        "### Build discourse graph network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phre608Fc4Bo",
        "outputId": "0a456216-f2d8-4986-c56a-ed66a2693c72"
      },
      "outputs": [],
      "source": [
        "# Create graph from TOMatrix (scipy sparse matrix)\n",
        "disc_graph = nx.from_scipy_sparse_matrix(disc_TOM)\n",
        "\n",
        "# Add tweet id's as node labels\n",
        "tweet_labels = dict(zip(disc_graph, tweet_keep))\n",
        "disc_graph = nx.relabel_nodes(disc_graph, tweet_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Basic graph description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byjn6NTOeE1A",
        "outputId": "091853a6-23f9-41bb-d4eb-faeb888af0bf"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "print(\"Nodes: \\t\\t\", disc_graph.number_of_nodes())\n",
        "print(\"Edges: \\t\\t\", disc_graph.number_of_edges())\n",
        "print(\"Isolates: \\t\", nx.number_of_isolates(disc_graph))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write the graph to a `.csv` file for later use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBQlft54ku60"
      },
      "outputs": [],
      "source": [
        "# Write edgelist to .csv\n",
        "nx.write_weighted_edgelist(disc_graph, path='NST04_discourse_graph.csv', delimiter=',')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xeroCdCmQ5H"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# remove isolates\n",
        "disc_graph.remove_nodes_from(list(nx.isolates(disc_graph)))\n",
        "# nx.draw(disc_graph, node_size=4)\n",
        "# nx.draw_networkx_nodes(disc_graph, pos=nx.spring_layout(disc_graph), node_size=4)\n",
        "# nx.draw_networkx_nodes(disc_graph, pos=nx.spectral_layout(disc_graph), node_size=4)\n",
        "# nx.draw_networkx_nodes(disc_graph, pos=nx.kamada_kawai_layout(disc_graph), node_size=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQqqnwdMbrOF"
      },
      "source": [
        "# Some exploratoration of features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLPDVYkr_E7C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "corrmat = discourse_feats_df[disc_cols].corr(method='spearman')\n",
        "f, ax = plt.subplots(figsize=(12, 10))\n",
        "sns.heatmap(corrmat, ax=ax, cmap=\"YlGnBu\", linewidths=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ke-JpDA_2n0"
      },
      "outputs": [],
      "source": [
        "discourse_feats_df[disc_cols].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q6q9M-oH5H_"
      },
      "outputs": [],
      "source": [
        "discourse_feat_df[disc_cols].sum(axis=1).plot(kind='hist')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIejhco6p_YO"
      },
      "source": [
        "# Community Detection\n",
        "\n",
        "The library `cdlib` requires `python >= 3.8.0` to allow all modules to work. Unfortunately, Google's colab currently uses `python == 3.7.10`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "hcxphj5gQPfZ",
        "outputId": "5a3e233c-ea85-4437-cc40-eca8f72ad458"
      },
      "outputs": [],
      "source": [
        "# cdlib requires Python verion at least 3.8.x\n",
        "\n",
        "from cdlib import algorithms, viz\n",
        "from community import community_louvain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following methods are appropriate for community detection in *weighted* ans *undirected* acyclic graphs. Each one searches a the local optima for number of clusters using a variety of heuristics.\n",
        "\n",
        "This code block optimizes parameters and selects the best clustering solution for each of four methods:\n",
        "* The \"Chinese Whispers\" fuzzy clustering algorithm ([Biemann 2006](https://dl.acm.org/doi/abs/10.5555/1654758.1654774))\n",
        "* The InfoMap methods of random walks ([Rosvall 2008](https://www.pnas.org/content/105/4/1118/))\n",
        "* The Louvain method of community modularity ([Blondel et. al. 2008](https://iopscience.iop.org/article/10.1088/1742-5468/2008/10/P10008/meta/))\n",
        "* The Leiden method improvement on Louvain ([Traag 2018](https://arxiv.org/abs/1810.08473/))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXrp3XcgqEAX",
        "outputId": "5cdbf4e4-7af6-4522-88de-65135b4de58e"
      },
      "outputs": [],
      "source": [
        "# load graph\n",
        "\n",
        "G = disc_graph\n",
        "\n",
        "# remove isolates\n",
        "G.remove_nodes_from(list(nx.isolates(G)))\n",
        "\n",
        "# Community detection methods for weighted acyclic graphs\n",
        "\n",
        "from cdlib import ensemble\n",
        "\n",
        "methods = [algorithms.chinesewhispers, algorithms.infomap, algorithms.louvain, algorithms.leiden]\n",
        "\n",
        "# Chinese whisper parameters\n",
        "iterations = ensemble.Parameter(name=\"iterations\", start=15, end=25, step=5)\n",
        "chinese_conf = [iterations]\n",
        "\n",
        "# Louvain parameters to search\n",
        "resolution = ensemble.Parameter(name=\"resolution\", start=0.5, end=1, step=0.1)\n",
        "randomize = ensemble.BoolParameter(name=\"randomize\")\n",
        "louvain_conf = [resolution, randomize]\n",
        "\n",
        "# Leiden parameters\n",
        "leiden_conf = [ensemble.BoolParameter(name='weights', value='weight')]\n",
        "\n",
        "# Loop through grid search and store best community in a list\n",
        "\n",
        "comms = []\n",
        "\n",
        "for coms, scoring in ensemble.pool_grid_filter(G, methods, [chinese_conf, [],louvain_conf, leiden_conf], quality_score=evaluation.erdos_renyi_modularity, aggregate=max):\n",
        "    print(\"%s\\nCommunities:\\t %s \\nConfiguration: %s \\nScoring: %s\\n\" %(coms.method_name, len(coms.communities), coms.method_parameters, scoring))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method `algorithms.chinesewhispers` performs best with a modularity score of $0.7855965109087125$, returning $9$ communities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comms_chinesewhispers = algorithms.chinesewhispers(G, weighting='top', iterations=15)\n",
        "comms_infomap = algorithms.infomap(G)\n",
        "comms_louvain = algorithms.louvain(G, resolution=0.6, randomize=True)\n",
        "comms_leiden = algorithms.leiden(G, weights='weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate `performance` for each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx.algorithms.community as nx_comm\n",
        "\n",
        "comms = [comms_louvain, comms_leiden, comms_infomap, comms_chinesewhispers]\n",
        "\n",
        "comm_perf = []\n",
        "\n",
        "for c in comms:\n",
        "    perf = nx_comm.performance(G, c.communities)\n",
        "    comm_perf.append(perf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Performance:\\n\", comm_perf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method `algorithms.chinesewhispers` performs best with a performance score of $0.9792224330305016$.\n",
        "\n",
        "It appears that the communities detected by `algorithms.chinesewhispers` are the optimal solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calulate PageRank for each node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "G_pr = nx.pagerank(G)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assign communities to Nodes and internal Edges\n",
        "\n",
        "Adapted from [Community detection using NetworkX](https://orbifold.net/default/community-detection-using-networkx/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_node_community(G, communities):\n",
        "    '''Add community to node attributes'''\n",
        "    for c, v_c in enumerate(communities):\n",
        "        for v in v_c:\n",
        "            # Add 1 to save 0 for external edges\n",
        "            G.nodes[v]['community'] = c + 1\n",
        "\n",
        "def set_edge_community(G):\n",
        "    '''Find internal edges and add their community to their attributes'''\n",
        "    for v, w, in G.edges:\n",
        "        if G.nodes[v]['community'] == G.nodes[w]['community']:\n",
        "            # Internal edge, mark with community\n",
        "            G.edges[v, w]['community'] = G.nodes[v]['community']\n",
        "        else:\n",
        "            # External edge, mark as 0\n",
        "            G.edges[v, w]['community'] = 0\n",
        "\n",
        "# Set node and edge communities\n",
        "set_node_community(G, comms_chinesewhispers.communities)\n",
        "set_edge_community(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create `pandas` dataframe of node attributes including assigned community and page rank.\n",
        "\n",
        "Adapted from [stackoverflow: Converting Networkx graph to data frame with its attributes](https://stackoverflow.com/a/62386579)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_node_df(G):\n",
        "    nodes = {}\n",
        "    for node, attribute in G.nodes(data=True):\n",
        "        if not nodes.get('node'):\n",
        "            nodes['node'] = [node]\n",
        "        else:\n",
        "            nodes['node'].append(node)\n",
        "\n",
        "        for key, value in attribute.items():\n",
        "            if not nodes.get(key):\n",
        "                nodes[key] = [value]\n",
        "            else:\n",
        "                nodes[key].append(value)\n",
        "\n",
        "    return pd.DataFrame(nodes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tweet_community_df = make_node_df(G)\n",
        "\n",
        "tweet_community_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweet_community_df['community'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tweet_pr_df = pd.DataFrame(list(G_pr.items()), columns=['id','page_rank'])\n",
        "\n",
        "tweet_pr_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discourse_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "output_df = discourse_df.join(tweet_community_df[['node','community']].set_index('node'), on='id')\n",
        "\n",
        "output_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_df = output_df.join(tweet_pr_df.set_index('id'), on='id')\n",
        "\n",
        "output_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_df['community'].fillna(-1, inplace=True)\n",
        "\n",
        "output_df['community'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_df['page_rank'].fillna(0, inplace=True)\n",
        "\n",
        "output_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "output_df.to_pickle('NST04_tweet_communities.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Graph and community visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "SSXx3TOps61a",
        "outputId": "e988af85-2dbe-4356-e428-7effef6d6e52"
      },
      "outputs": [],
      "source": [
        "# draw the graph of communities\n",
        "\n",
        "viz.plot_community_graph(G, comms_chinesewhispers, plot_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate node positions, spring\n",
        "\n",
        "pos = nx.spring_layout(G, k=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.rcParams.update(plt.rcParamsDefault)\n",
        "plt.rcParams.update({'figure.figsize': (15, 10)})\n",
        "# plt.style.use('dark_background')\n",
        "\n",
        "# set node color by community\n",
        "node_color = [get_color(G.nodes[v]['community']) for v in G.nodes]\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos=pos, node_size=8, node_color= node_color, alpha=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_color(i, r_off=1, g_off=1, b_off=1):\n",
        "    '''Assign a color to a vertex.'''\n",
        "    r0, g0, b0 = 0, 0, 0\n",
        "    n = 16\n",
        "    low, high = 0.1, 0.9\n",
        "    span = high - low\n",
        "    r = low + span * (((i + r_off) * 3) % n) / (n - 1)\n",
        "    g = low + span * (((i + g_off) * 5) % n) / (n - 1)\n",
        "    b = low + span * (((i + b_off) * 7) % n) / (n - 1)\n",
        "    return (r, g, b)            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.rcParams.update(plt.rcParamsDefault)\n",
        "plt.rcParams.update({'figure.figsize': (15, 10)})\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "# Set community color for internal edges\n",
        "external = [(v, w) for v, w in G.edges if G.edges[v, w]['community'] == 0]\n",
        "internal = [(v, w) for v, w in G.edges if G.edges[v, w]['community'] > 0]\n",
        "internal_color = [\"black\" for e in internal]\n",
        "node_color = [get_color(G.nodes[v]['community']) for v in G.nodes]\n",
        "\n",
        "# external edges\n",
        "nx.draw_networkx(\n",
        "    G, \n",
        "    pos=pos, \n",
        "    node_size=0, \n",
        "    edgelist=external, \n",
        "    edge_color=\"silver\",\n",
        "    node_color=node_color,\n",
        "    alpha=0.2, \n",
        "    with_labels=False)\n",
        "\n",
        "# internal edges\n",
        "nx.draw_networkx(\n",
        "    G, \n",
        "    pos=pos, \n",
        "    edgelist=internal, \n",
        "    edge_color=internal_color,\n",
        "    node_color=node_color,\n",
        "    alpha=0.05, \n",
        "    with_labels=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IQqqnwdMbrOF"
      ],
      "machine_shape": "hm",
      "name": "04_NST_Networks.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "a7310ae5507b01abd95ea46fd2558c5cb8ed651a13b81d24a3b6cf995e985ef9"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('piper_env': venv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
